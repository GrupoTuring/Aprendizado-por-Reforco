
# üé∞ Bandits (Roletas)

  
## Resumo do Problema

Um dos problemas mais cl√°ssicos e simples em aprendizado por refor√ßo √© o problema do *k*-armed Bandit (em portugu√™s, Roleta de *k*-alavancas). Nele uma intelig√™ncia artificial iria para um cassino e encontraria uma roleta com *k* alavancas, l√° ela teria que aprender - por meio de aprendizado por refor√ßo - a escolher a alavanca que lhe da mais dinheiro.

  

## Especificando o Problema

Este problema pode ser generalizado para qualquer situa√ß√£o em que um agente √© apresentado a um n√∫mero *k* de escolhas. Ap√≥s cada escolha esse agente recebe uma recompensa dentro de uma **distribui√ß√£o probabil√≠stica estacion√°ria** baseado na a√ß√£o escolhida. A imagem a seguir tenta ilustrar o problema:
  
![gr√°fico representado a distribui√ß√£o normal de um 10 armed bandit](s&b_bandit.png)

No nosso problema de *k*-armed Bandit para cada das *k* a√ß√µes h√° uma recompensa m√©dia **esperada**; esse valor **esperado** geralmente √© chamado de o **valor** da a√ß√£o. Ou seja, definimos o **valor** de uma a√ß√£o arbitr√°ria *&alpha;*, denotado de *q*<sub>\*</sub>(*&alpha;*), como uma recompensa em um tempo *t* (*R*<sub>t</sub>) dado que a a√ß√£o em *t* (*A*<sub>*t*</sub>) foi *a* como:

<a href="https://www.codecogs.com/eqnedit.php?latex=q_*(a)&space;=&space;\mathop{\mathbb{E}}[R_t&space;|&space;A_t&space;=&space;a]" target="_blank"><img src="https://latex.codecogs.com/gif.latex?q_*(a)&space;=&space;\mathop{\mathbb{E}}[R_t&space;|&space;A_t&space;=&space;a]" title="q_*(a) = \mathop{\mathbb{E}}[R_t | A_t = a]" /></a> (Esse <a href="https://www.codecogs.com/eqnedit.php?latex=\mathop{\mathbb{E}}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\mathop{\mathbb{E}}" title="\mathop{\mathbb{E}}" /></a> significa o valor esperado, √© como se fosse a "recompensa m√©dia" - a recompensa com maior probabilidade de acontecer dado *&alpha;*.)

Se nosso agente soubesse todos os valores esperados, o problema seria facilmente resolvido: ele simplesmente escolheria a a√ß√£o com o maior valor, o problema √©  justamente que ele n√£o sabe esses valores. E para descobri-los ele necessitar√° realizar o que chamamos de **explora√ß√£o e explota√ß√£o**.

Na **explora√ß√£o** ele tentar√° conhecer melhor os valores de cada a√ß√£o, para que na **explota√ß√£o** ele j√° conhe√ßa uma variedade de valores diferentes e assim poder√° escolher os melhores. Uma analogia com o mundo real seria o menu de um restaurante: imagine que voc√™ pediu um prato l√° e acabou gostando deste prato, voc√™ poderia sempre pedi-lo quando fosse nesse restaurante e acabaria feliz, por√©m, se n√£o se arriscar a pedir nenhum outro prato nuca saber√° se pode haver um prato do qual voc√™ acabe gostando mais! 

## Estimando os *Q*-Valores

  

Como nosso agente n√£o conhece os *q*-valores reais cabe a ele tentar estima-los de alguma maneira. Como estamos buscando um **valor esperado** - ou seja, a recompensa m√©dia - basta calcularmos a m√©dia das recompensas recebidas por nosso agente naquela a√ß√£o:

<a href="https://www.codecogs.com/eqnedit.php?latex=Q_{n&plus;1}&space;=\frac{1}{n}&space;\sum_{i=1}^{n}&space;R_i" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Q_{n&plus;1}&space;=\frac{1}{n}&space;\sum_{i=1}^{n}&space;R_i" title="Q_{n+1} =\frac{1}{n} \sum_{i=1}^{n} R_i" /></a>

Por√©m, como na computa√ß√£o seria custoso executar uma somat√≥ria toda vez que gostar√≠amos de atualizar *Q* podemos fazer algumas manipula√ß√µes alg√©bricas e cair na seguinte equa√ß√£o:

<a href="https://www.codecogs.com/eqnedit.php?latex=Q_{n&plus;1}&space;=&space;Q_n&space;&plus;&space;\frac{1}{n}(R_n&space;-&space;Q_n)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Q_{n&plus;1}&space;=&space;Q_n&space;&plus;&space;\frac{1}{n}(R_n&space;-&space;Q_n)" title="Q_{n+1} = Q_n + \frac{1}{n}(R_n - Q_n)" /></a>

Que √© a equa√ß√£o que utilizaremos em nosso algoritmos para estimar *Q*! Lembre-se que *n* nesse caso vai ser o *n√∫mero de vezes que aquela a√ß√£o ocorreu*. Ent√£o teremos um *n* para cada a√ß√£o.

## Algoritmos Para Este Problema

[Algoritmo Guloso](Agente%20Guloso) - Um algoritmo que s√≥ faz **explota√ß√£o**.

[Algoritmo &epsilon;-Guloso](Agente%20Epsilon-Guloso) - Um algoritmo que mostra como **explora√ß√£o** √© importante.

[Algoritmo com UCB](Limite%20de%20Confian√ßa%20Superior) - Um algoritmo que utiliza um par√¢metro de **confian√ßa** para **explorar e explotar**.

[Algoritmo de Softmax]() - :construction_worker: :construction:

[Algoritmo de Elimina√ß√£o M√©dia]() - :construction_worker: :construction:

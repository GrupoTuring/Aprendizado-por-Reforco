
# üìà Algoritmo de Limite de Confian√ßa Superior (UCB)

## Ideia do Algoritmo
A ideia deste algoritmo √© utilizar uma fun√ß√£o matem√°tica que avalia a√ß√µes tomadas com menos frequ√™ncia de tal maneira que incentive o agente a peg√°-las, incentivando a **explora√ß√£o**.
A fun√ß√£o √© dada desta maneira:

$UCB_a = Q_t(a) + c \sqrt{\frac{\ln(t)}{N_t(a)}}$ de $a=1$ at√© $k$.

Onde: 
$Q_t(a)$ √© o valor estimado da a a√ß√£o $a$ no tempo $t$
$c$ √© o par√¢metro que controla a **desconfian√ßa**.
$t$ √© o n√∫mero de itera√ß√µes que ocorreram.
$N_t(a)$ √© o n√∫mero de vezes que a a√ß√£o $a$ foi escolhida at√© o tempo $t$.

Ent√£o aplica-se a fun√ß√£o em $Q_t(a)$ de $a=1$ at√© $k$ e utiliza-se a fun√ß√£o $argmax(UCB)$, assim obtendo o √≠ndice do maior valor ap√≥s $UCB$ ser aplicado em $Q_t$.

## Entendo a fun√ß√£o
A parte da fun√ß√£o que est√° dentro da raiz quadrada √© a **desconfian√ßa**. Conforme $N_t(a)$ cresce - como ele est√° no denominador - o valor da **desconfian√ßa** ca√≠. Analogamente, quando $t$ cresce, o valor aumenta. Por√©m, como ele est√° dentro de um logaritmo, isso significa que seus aumentos ser√£o bem menores com o passar do tempo. O par√¢metro $c$ ajuda a definir o qu√£o relevante essa desconfian√ßa ser√°.

Isso significa que nas primeiras itera√ß√µes o valor de **desconfian√ßa** ser√° maior, principalmente para a√ß√µes menos frequentes, e como essa desconfian√ßa √© somada aos $Q$ valores estimados por nosso agente, a fun√ß√£o $argmax(Q_t)$ ir√° priorizar essas a√ß√µes. Assim, conforme o agente faz mais a√ß√µes, como $ln(t)$ crescera bem menos, enquanto $N_t(a)$ continuar√° crescendo normalmente, o valor de **desconfian√ßa** ca√≠ra bastante, tornando assim os valores **conhecidos**.

## Pseudo C√≥digo do Algoritmo
```
inicialize de a = 1 at√© k:
  Q(a) <- 0 
  N(a) <- 0 
Percorra com t para sempre:
  Fa√ßa de a = 1 at√© k:
    UCB(a) = Q(a) + c * sqrt(ln(t)/N(A))
  A <- argmax(UCB)
  R <- bandit(A) #puxa a alavanca A
  N(A) <- N(A) + 1
  Q(A) <- Q(A) + [R - Q(A)]/N(A) 
 ```

## Problema do Algoritmo
Esse algoritmo √© uma solu√ß√£o excelente para o problema de $k$-Armed Bandit, e √© esse o problema; ele √© muito bom apenas para esse problema. Se mudarmos o problema para algo com uma **distribui√ß√£o probabil√≠stica n√£o estacion√°ria** (ou seja, que o valor esperado de cada a√ß√£o muda) esse algoritmo se demonstra ineficaz.

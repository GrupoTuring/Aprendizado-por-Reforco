# üìÖ Temporal-Difference Learning

M√©todos de **Temporal-Difference** s√£o algoritmos de Aprendizado por Refor√ßo que aprendem utilizando principalmente t√©cnicas de *bootstrapping* (uma estimativa a base de amostragem) da sua fun√ß√£o de valor. Esses m√©todos amostram do ambiente, assim como m√©todos de Monte Carlo, mas fazem atualiza√ß√µes com base em estimativas intermedi√°rias. Ou seja, enquanto m√©todos de Monte Carlo atualizam as suas predi√ß√µes apenas no fim do epis√≥dio (quando todos os retornos j√° s√£o conhecidos), m√©todos de  **Temporal-Difference** atualizam as suas predi√ß√µes a cada instante de tempo, utilizando *bootstrapping* para estimar o retorno do epis√≥dio.

## Algoritmos

 - [Q-Learning](Q-Learning)

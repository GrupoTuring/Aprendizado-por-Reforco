# üìÖ Temporal-Difference Learning

M√©todos de Temporal-Difference s√£o algoritmos de Aprendizado por Refor√ßo que aprendem utilizando principalmente t√©cnicas de bootstrapping (uma estimativa a base de amostragem) da sua fun√ß√£o de valor. Esses m√©todos amostram do ambiente (assim como m√©todos de Monte Carlo), mas fazem atualiza√ß√µes com base em estimativas atuais. Ou seja, enquanto m√©todos de Monte Carlo atualizam apenas quando a sa√≠da final j√° √© sabida, Temporal-Difference atualiza as predi√ß√µes para representarem valores mais tardios sobre o futuro antes do resultado final j√° ser conhecido.

## Algoritmos

 - [Q-Learning](Q-Learning)

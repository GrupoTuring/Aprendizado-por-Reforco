{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('torch': conda)",
   "display_name": "Python 3.8.5 64-bit ('torch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a5cd74ba85a3b6a037c59ac3f3634fcdd9437555c9fe253dd51f04000fcd493e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximal Policy Optimization (PPO)\n",
    "\n",
    "Como vimos na aula de A2C, uma função objetivo muito utilizada é:\n",
    "\n",
    "$$\n",
    "    J(\\theta) =  \\mathbb{E}_{s,a\\sim\\pi_\\theta} [A^{\\pi_\\theta}_w(s,a)], \\qquad\n",
    "    \\nabla_\\theta J(\\theta) =  \\mathbb{E}_{s,a\\sim\\pi_\\theta} [\\nabla_\\theta \\log \\pi_\\theta(a|s)\\cdot A^{\\pi_\\theta}_w(s,a)].\n",
    "$$\n",
    "\n",
    "Os índices na função _advantage_ $A$ indicam que $A$ depende tanto dos pesos $w$ utilizados para calcular o estimar de cada estado, quanto da política $\\pi_\\theta$, que determina quais trajetórias o agente vai seguir dentro do ambiente.\n",
    "\n",
    "> Obs: pode-se mostrar que essa formulação é equivalente à formulação que utiliza somatórias no tempo:\n",
    "$$\n",
    "    J(\\theta) =  \\mathbb{E}_{(s_0,a_0,\\dots)\\sim\\pi_\\theta} \\left[\\sum_{t=0}^\\infty \\gamma^t A^{\\pi_\\theta}_w(s_t,a_t)\\right], \\qquad\n",
    "    \\nabla_\\theta J(\\theta) =  \\mathbb{E}_{(s_0,a_0,\\dots)\\sim\\pi_\\theta} \\left[\\sum_{t=0}^\\infty \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t)\\cdot A^{\\pi_\\theta}_w(s_t,a_t)\\right].\n",
    "$$\n",
    "\n",
    "Note que uma pequena variação no espaço de parâmetros ($\\Delta\\theta = \\alpha\\nabla_\\theta J$) pode causar uma grande variação no espaço de políticas. Isso significa que, em geral, a taxa de aprendizado $\\alpha$ não pode ser muito alta; caso contrário, corremos o risco de obter uma nova política que não funcione. Consequentemente, a eficiência amostral de A2C também é limitada.\n",
    "\n",
    "\n",
    "## Trust Region Policy Optimization (TRPO)\n",
    "\n",
    "Uma maneira de resolver esse problema é limitar as variações na política. Para isso, vamos utilizar a divergência KL $KL(\\pi_1 || \\pi_2)$, que pode ser, simplificadamente, encarada como uma medida da diferença entre duas políticas (ou, em geral, duas distribuições de probabilidade).\n",
    "\n",
    "TRPO define uma região de confiança (trust region) para garantir que a política nova não se distancie demais da política antiga:\n",
    "$$E_{s\\sim\\pi_{\\theta_{\\mathrm{old}}}}\\bigl[KL\\bigl(\\pi_{\\mathrm{old}}(\\cdot|s)\\,||\\,\\pi(\\cdot|s)\\bigr)\\bigr] \\le \\delta.$$\n",
    "\n",
    "No entanto, maximizar a função objetivo de A2C sujeito a essas restrições é um pouco complicado. Então, vamos utilizar uma aproximação da função objetivo de A2C:\n",
    "\n",
    "$$L(\\theta_{\\mathrm{old}},\\theta) = E_{s,a\\sim\\pi_{\\theta_{\\mathrm{old}}}} \\left[\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)} A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a)\\right].$$\n",
    "\n",
    "Ou seja, TRPO consiste em:\n",
    "$$\\text{maximizar } E_{s,a\\sim\\pi_{\\theta_{\\mathrm{old}}}} \\left[\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)} A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a)\\right] \\text{ sujeito a } E_{s\\sim\\pi_{\\theta_{\\mathrm{old}}}}\\bigl[KL\\bigl(\\pi_{\\mathrm{old}}(\\cdot|s)\\,||\\,\\pi(\\cdot|s)\\bigr)\\bigr] \\le \\delta.$$\n",
    "\n",
    "> Para entender como chegamos $L(\\theta_{\\mathrm{old}},\\theta)$ é uma aproximação de $J(\\theta)$, podemos fazer:\n",
    "\\begin{align*}\n",
    "J(\\theta) &= E_{\\pi_\\theta}[A^{\\pi_\\theta}(s,a)] \\\\\n",
    "        &= E_{\\pi_\\theta}[A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a)] \\\\\n",
    "\t\t&= \\sum_{s,a} \\rho_{\\pi_\\theta}(s)\\cdot \\pi_\\theta(a|s) \\cdot A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a) \\\\\n",
    "\t\t&= \\sum_{s,a} \\rho_{\\pi_\\theta}(s)\\cdot \\pi_{\\theta_{\\mathrm{old}}}(a|s) \\cdot \\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)}A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a) \\\\\n",
    "\t\t&\\approx \\sum_{s,a} \\rho_{\\pi_{\\theta_{\\mathrm{old}}}}(s)\\cdot \\pi_{\\theta_{\\mathrm{old}}}(a|s) \\cdot \\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)}A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a) \\\\\n",
    "\t\t&= E_{\\pi_{\\theta_{\\mathrm{old}}}} \\left[\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)} A^{\\pi_\\theta}(s,a)\\right]\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "## Proximal Policy Optimization (PPO)\n",
    "\n",
    "Como já foi mencionado, a restrição ($KL < \\delta$) imposta em TRPO torna o algoritmo relativamente complicado. PPO é uma tentativa de simplificar esse algoritmo. Ao invés de utilizar trust regions, PPO mexe diretamente com a função objetivo:\n",
    "\n",
    "$$\n",
    "    L(\\theta_{\\mathrm{old}},\\theta) = E_{s,a\\sim\\pi_{\\theta_{\\mathrm{old}}}} \\Bigl[\\min\\left(r A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a),\\, \\operatorname{clip}(r,1-\\varepsilon,1+\\varepsilon) A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a)\\right)\\Bigr],\n",
    "    \\quad\n",
    "    r = \\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)}.\n",
    "$$\n",
    "Essa função pode ser reescrita como:\n",
    "$$\n",
    "    L(\\theta_{\\mathrm{old}},\\theta) = E_{s,a\\sim\\pi_{\\theta_{\\mathrm{old}}}} \\Bigl[\\min\\left(r A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a),\\, g(\\varepsilon, A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a))\\right)\\Bigr],\n",
    "    \\quad\n",
    "    g(\\varepsilon, A) = \\begin{cases}\n",
    "        (1+\\varepsilon) A, & A \\ge 0 \\\\\n",
    "        (1-\\varepsilon) A,  & A < 0.\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "Nota-se que:\n",
    "- Quando a vantagem é positiva, se $r$ aumentar, então $L$ aumenta. No entanto, esse benefício é limitado pelo clip: se $r > 1+\\varepsilon$, não há mais benefício para $r$ aumentar.\n",
    "- Quando a vantagem é positiva, se $r$ diminuir, então $L$ aumenta. No entanto, esse benefício é limitado pelo clip: se $r M 1-\\varepsilon$, não há mais benefício para $r$ diminuir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Divida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, observation_shape, action_shape):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.policy1 = nn.Linear(observation_shape, 64)\n",
    "        self.policy2 = nn.Linear(64, 64)\n",
    "        self.policy3 = nn.Linear(64, action_shape)\n",
    "        \n",
    "        self.value1 = nn.Linear(observation_shape, 64)\n",
    "        self.value2 = nn.Linear(64, 64)\n",
    "        self.value3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        dists = torch.tanh(self.policy1(state))\n",
    "        dists = torch.tanh(self.policy2(dists))\n",
    "        dists = F.softmax(self.policy3(dists), dim=-1)\n",
    "        probs = Categorical(dists)\n",
    "        \n",
    "        v = torch.tanh(self.value1(state))\n",
    "        v = torch.tanh(self.value2(v))\n",
    "        v = self.value3(v)\n",
    "\n",
    "        return probs, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ExperienceReplay:\n",
    "    \"\"\"Experience Replay Buffer para A2C.\"\"\"\n",
    "    def __init__(self, max_length, observation_space):\n",
    "        \"\"\"Cria um Replay Buffer.\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        max_length: int\n",
    "            Tamanho máximo do Replay Buffer.\n",
    "        observation_space: int\n",
    "            Tamanho do espaço de observação.\n",
    "        \"\"\"\n",
    "        self.length = 0\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.states = np.zeros((max_length, observation_space), dtype=np.float32)\n",
    "        self.actions = np.zeros((max_length), dtype=np.int32)\n",
    "        self.rewards = np.zeros((max_length), dtype=np.float32)\n",
    "        self.next_states = np.zeros((max_length, observation_space), dtype=np.float32)\n",
    "        self.dones = np.zeros((max_length), dtype=np.float32)\n",
    "        self.logp = np.zeros((max_length), dtype=np.float32)\n",
    "\n",
    "    def update(self, states, actions, rewards, next_states, dones, logp):\n",
    "        \"\"\"Adiciona uma experiência ao Replay Buffer.\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        state: np.array\n",
    "            Estado da transição.\n",
    "        action: int\n",
    "            Ação tomada.\n",
    "        reward: float\n",
    "            Recompensa recebida.\n",
    "        state: np.array\n",
    "            Estado seguinte.\n",
    "        done: int\n",
    "            Flag indicando se o episódio acabou.\n",
    "        \"\"\"\n",
    "        self.states[self.length] = states\n",
    "        self.actions[self.length] = actions\n",
    "        self.rewards[self.length] = rewards\n",
    "        self.next_states[self.length] = next_states\n",
    "        self.dones[self.length] = dones\n",
    "        self.logp[self.length] = logp\n",
    "        self.length += 1\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Retorna um batch de experiências.\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            Tamanho do batch de experiências.\n",
    "\n",
    "        Retorna\n",
    "        -------\n",
    "        states: np.array\n",
    "            Batch de estados.\n",
    "        actions: np.array\n",
    "            Batch de ações.\n",
    "        rewards: np.array\n",
    "            Batch de recompensas.\n",
    "        next_states: np.array\n",
    "            Batch de estados seguintes.\n",
    "        dones: np.array\n",
    "            Batch de flags indicando se o episódio acabou.\n",
    "        \"\"\"\n",
    "        self.length = 0\n",
    "\n",
    "        return (self.states, self.actions, self.rewards, self.next_states, self.dones, self.logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class PPO:\n",
    "    def __init__(self, observation_space, action_space, lr=7e-4, gamma=0.99, lam=0.95, vf_coef=0.5, entropy_coef=0.005,clip_param =0.2, epochs =10, n_steps=5):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "        self.vf_coef = vf_coef\n",
    "        self.entropy_coef = entropy_coef\n",
    "        self.clip_param = clip_param\n",
    "        self.epochs = epochs\n",
    "\n",
    "        self.n_steps = n_steps\n",
    "        self.memory = ExperienceReplay(n_steps, observation_space.shape[0])\n",
    "\n",
    "        self.actorcritic = ActorCritic(observation_space.shape[0], action_space.n).to(self.device)\n",
    "        self.actorcritic_optimizer = optim.Adam(self.actorcritic.parameters(), lr=lr)\n",
    "\n",
    "    def act(self, state):\n",
    "        state = torch.FloatTensor(state).to(self.device).unsqueeze(0)\n",
    "        probs, _ = self.actorcritic.forward(state)\n",
    "        action = probs.sample()\n",
    "        log_prob = probs.log_prob(action)\n",
    "        return action.cpu().detach().item(), log_prob\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done, logp):\n",
    "        self.memory.update(state, action, reward, next_state, done, logp)\n",
    "\n",
    "    def compute_gae(self, rewards, dones, v, v2):\n",
    "        T = len(rewards)\n",
    "\n",
    "        returns = torch.zeros_like(rewards)\n",
    "        gaes = torch.zeros_like(rewards)\n",
    "        \n",
    "        future_gae = torch.tensor(0.0, dtype=rewards.dtype)\n",
    "        next_return = torch.tensor(v2[-1], dtype=rewards.dtype)\n",
    "\n",
    "        not_dones = 1 - dones\n",
    "        deltas = rewards + not_dones * self.gamma * v2 - v\n",
    "\n",
    "        for t in reversed(range(T)):\n",
    "            returns[t] = next_return = rewards[t] + self.gamma * not_dones[t] * next_return\n",
    "            gaes[t] = future_gae = deltas[t] + self.gamma * self.lam * not_dones[t] * future_gae\n",
    "\n",
    "        gaes = (gaes - gaes.mean()) / (gaes.std() + 1e-8) # Normalização\n",
    "\n",
    "        return gaes, returns\n",
    "\n",
    "    def train(self):\n",
    "        if self.memory.length < self.n_steps:\n",
    "            return\n",
    "\n",
    "        (states, actions, rewards, next_states, dones, old_logp) = self.memory.sample()\n",
    "\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.FloatTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).unsqueeze(-1).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).unsqueeze(-1).to(self.device)\n",
    "        old_logp = torch.FloatTensor(old_logp).to(self.device)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            probs, v = self.actorcritic.forward(states)\n",
    "            with torch.no_grad():\n",
    "                _, v2 = self.actorcritic.forward(next_states)\n",
    "\n",
    "            new_logp = probs.log_prob(actions)\n",
    "\n",
    "            advantages, returns = self.compute_gae(rewards, dones, v, v2)\n",
    "\n",
    "            ratio = (new_logp.unsqueeze(-1) - old_logp.unsqueeze(-1)).exp()\n",
    "            surr1 = ratio * advantages.detach()\n",
    "            surr2 = torch.clamp(ratio, 1.0 - self.clip_param, 1.0 + self.clip_param) * advantages.detach()\n",
    "\n",
    "            entropy = probs.entropy().mean()\n",
    "\n",
    "            policy_loss =   - torch.min(surr1,surr2).mean()\n",
    "            value_loss =    self.vf_coef * F.mse_loss(v, returns.detach())\n",
    "            entropy_loss = -self.entropy_coef * entropy\n",
    "\n",
    "            self.actorcritic_optimizer.zero_grad()\n",
    "            (policy_loss + entropy_loss + value_loss).backward()\n",
    "            self.actorcritic_optimizer.step()\n",
    "\n",
    "        return policy_loss + entropy_loss + value_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import deque\n",
    "\n",
    "def train(agent, env, total_timesteps):\n",
    "    total_reward = 0\n",
    "    episode_returns = deque(maxlen=20)\n",
    "    avg_returns = []\n",
    "\n",
    "    state = env.reset()\n",
    "    timestep = 0\n",
    "    episode = 0\n",
    "\n",
    "    while timestep < total_timesteps:\n",
    "        action, log_prob = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.remember(state, action, reward, next_state, done, log_prob.detach().cpu().numpy())\n",
    "        loss = agent.train()\n",
    "        timestep += 1\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "        if done:\n",
    "            episode_returns.append(total_reward)\n",
    "            episode += 1\n",
    "            next_state = env.reset()\n",
    "\n",
    "        if episode_returns:\n",
    "            avg_returns.append(np.mean(episode_returns))\n",
    "\n",
    "        total_reward *= 1 - done\n",
    "        state = next_state\n",
    "\n",
    "        ratio = math.ceil(100 * timestep / total_timesteps)\n",
    "\n",
    "        avg_return = avg_returns[-1] if avg_returns else np.nan\n",
    "        \n",
    "        print(f\"\\r[{ratio:3d}%] timestep = {timestep}/{total_timesteps}, episode = {episode:3d}, avg_return = {avg_return:10.4f}\", end=\"\")\n",
    "\n",
    "    return avg_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[100%] timestep = 75000/75000, episode = 480, avg_return =   265.2000"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "agente = PPO(env.observation_space, env.action_space)\n",
    "returns = train(agente, env, 75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 375.2875 248.518125\" width=\"375.2875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-11-01T17:56:04.930085</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 375.2875 248.518125 \nL 375.2875 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 224.64 \nL 368.0875 224.64 \nL 368.0875 7.2 \nL 33.2875 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m03bca368e2\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.505682\" xlink:href=\"#m03bca368e2\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(45.324432 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"89.119991\" xlink:href=\"#m03bca368e2\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10000 -->\n      <g transform=\"translate(73.213741 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.734301\" xlink:href=\"#m03bca368e2\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 20000 -->\n      <g transform=\"translate(113.828051 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"170.348611\" xlink:href=\"#m03bca368e2\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 30000 -->\n      <g transform=\"translate(154.442361 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"210.96292\" xlink:href=\"#m03bca368e2\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 40000 -->\n      <g transform=\"translate(195.05667 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"251.57723\" xlink:href=\"#m03bca368e2\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 50000 -->\n      <g transform=\"translate(235.67098 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"292.19154\" xlink:href=\"#m03bca368e2\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 60000 -->\n      <g transform=\"translate(276.28529 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"332.805849\" xlink:href=\"#m03bca368e2\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 70000 -->\n      <g transform=\"translate(316.899599 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m5f884e7d90\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m5f884e7d90\" y=\"218.502759\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0 -->\n      <g transform=\"translate(19.925 222.301978)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m5f884e7d90\" y=\"178.218935\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 182.018153)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m5f884e7d90\" y=\"137.93511\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 200 -->\n      <g transform=\"translate(7.2 141.734329)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m5f884e7d90\" y=\"97.651286\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 300 -->\n      <g transform=\"translate(7.2 101.450504)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m5f884e7d90\" y=\"57.367461\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 400 -->\n      <g transform=\"translate(7.2 61.16668)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m5f884e7d90\" y=\"17.083636\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 500 -->\n      <g transform=\"translate(7.2 20.882855)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p18bd3fa325)\" d=\"M 48.505682 194.332465 \nL 48.55848 194.332465 \nL 48.676262 210.284859 \nL 48.720938 210.284859 \nL 48.838719 211.5538 \nL 48.871211 211.5538 \nL 48.984931 211.744029 \nL 48.993054 211.744029 \nL 49.106774 211.211387 \nL 49.151449 211.211387 \nL 49.228617 210.445994 \nL 49.265169 210.479564 \nL 49.419504 210.538957 \nL 49.533224 210.273349 \nL 49.646944 210.273349 \nL 49.760664 209.262657 \nL 49.988104 209.326999 \nL 50.105886 209.579892 \nL 50.138377 209.579892 \nL 50.219606 210.385569 \nL 50.252097 210.264717 \nL 50.280527 210.264717 \nL 50.398309 210.023014 \nL 50.406432 210.023014 \nL 50.503906 209.882021 \nL 50.520152 209.902163 \nL 50.581073 209.942447 \nL 50.751653 211.150961 \nL 50.755715 211.150961 \nL 50.901926 212.480328 \nL 50.918172 212.480328 \nL 51.035953 213.024159 \nL 51.117182 213.124869 \nL 51.247148 213.729126 \nL 51.320253 213.789552 \nL 51.438035 214.131964 \nL 51.612677 214.212532 \nL 51.734519 214.353525 \nL 52.112233 214.313242 \nL 52.225953 213.567991 \nL 52.230014 213.567991 \nL 52.343734 213.205436 \nL 52.38841 213.205436 \nL 52.50213 212.621321 \nL 52.563051 212.621321 \nL 52.676771 211.956638 \nL 52.725509 211.956638 \nL 52.839229 211.110678 \nL 52.940764 211.110678 \nL 53.054484 210.627272 \nL 53.139775 210.627272 \nL 53.253495 209.801453 \nL 53.338785 209.801453 \nL 53.452505 209.015919 \nL 53.692129 209.015919 \nL 53.805849 207.444849 \nL 53.830218 207.444849 \nL 53.943938 206.941302 \nL 53.968306 206.941302 \nL 54.082027 206.175909 \nL 54.155132 206.175909 \nL 54.268852 205.893922 \nL 54.281037 205.893922 \nL 54.394757 205.511226 \nL 54.500354 205.511226 \nL 54.614074 204.60484 \nL 54.727794 204.60484 \nL 54.841514 203.75888 \nL 54.853698 203.75888 \nL 54.967418 203.335899 \nL 54.979603 203.335899 \nL 55.093323 202.81221 \nL 55.182674 202.81221 \nL 55.296394 203.315757 \nL 55.410114 203.315757 \nL 55.523835 203.517177 \nL 55.544142 203.517177 \nL 55.657862 203.718596 \nL 55.76752 203.718596 \nL 55.88124 203.416467 \nL 55.934039 203.416467 \nL 56.047759 203.013629 \nL 56.165541 203.013629 \nL 56.279261 202.510081 \nL 56.648851 202.510081 \nL 56.762571 201.100147 \nL 57.4124 201.100147 \nL 57.52612 198.300421 \nL 57.688577 198.300421 \nL 57.802297 198.683118 \nL 57.993185 198.723401 \nL 58.106905 198.542124 \nL 58.395266 198.542124 \nL 58.508986 197.011339 \nL 58.622706 197.011339 \nL 58.736426 196.346656 \nL 58.955744 196.346656 \nL 59.069464 195.319418 \nL 59.296904 195.319418 \nL 59.410624 194.715161 \nL 59.459361 194.715161 \nL 59.573081 195.037431 \nL 59.670556 195.037431 \nL 59.784276 194.614451 \nL 59.958917 194.614451 \nL 60.072637 193.808775 \nL 60.267586 193.808775 \nL 60.381306 192.781537 \nL 60.442227 192.781537 \nL 60.555947 192.418983 \nL 61.002705 192.418983 \nL 61.116425 190.183231 \nL 61.607858 190.183231 \nL 61.721578 187.766201 \nL 62.03837 187.766201 \nL 62.15209 186.295842 \nL 62.558233 186.295842 \nL 62.671953 184.825482 \nL 63.069973 184.825482 \nL 63.183693 183.113419 \nL 63.841645 183.113419 \nL 63.955365 180.434545 \nL 64.048778 180.434545 \nL 64.162498 181.804195 \nL 64.207174 181.804195 \nL 64.320894 184.80534 \nL 64.381815 184.80534 \nL 64.495536 185.308888 \nL 64.79202 185.308888 \nL 64.90574 183.919096 \nL 65.429665 183.919096 \nL 65.543385 181.622918 \nL 65.945466 181.622918 \nL 66.059186 181.058944 \nL 66.63591 181.038802 \nL 66.74963 180.414403 \nL 66.908026 180.414403 \nL 67.021746 180.756816 \nL 67.68782 180.756816 \nL 67.80154 177.695245 \nL 68.394509 177.695245 \nL 68.508229 175.237932 \nL 69.117444 175.237932 \nL 69.231164 173.082747 \nL 71.148159 173.082747 \nL 71.26188 164.542576 \nL 71.976691 164.542576 \nL 72.090411 161.299728 \nL 72.240684 161.299728 \nL 72.354404 162.770088 \nL 72.663073 162.770088 \nL 72.776793 163.676474 \nL 73.528158 163.676474 \nL 73.641878 161.521289 \nL 74.722219 161.581715 \nL 74.835939 160.715613 \nL 75.144608 160.715613 \nL 75.258328 162.447817 \nL 75.595426 162.447817 \nL 75.709146 161.239303 \nL 75.835051 161.239303 \nL 75.948771 160.836464 \nL 76.074675 160.836464 \nL 76.188395 160.514194 \nL 76.509248 160.514194 \nL 76.622968 160.393342 \nL 77.293104 160.393342 \nL 77.406825 159.668234 \nL 77.557097 159.668234 \nL 77.670818 160.917032 \nL 77.857643 160.917032 \nL 77.971363 160.57462 \nL 78.174435 160.57462 \nL 78.288155 161.279586 \nL 78.576517 161.279586 \nL 78.690237 160.635045 \nL 78.966414 160.635045 \nL 79.080134 162.568669 \nL 79.697472 162.568669 \nL 79.811192 162.447817 \nL 80.302625 162.447817 \nL 80.416345 163.031933 \nL 80.509758 163.031933 \nL 80.623478 175.963041 \nL 80.984945 175.963041 \nL 81.098665 175.137222 \nL 81.261123 175.137222 \nL 81.374843 175.862331 \nL 81.630713 175.862331 \nL 81.744433 178.319644 \nL 83.336514 178.319644 \nL 83.450234 177.876522 \nL 83.734534 177.876522 \nL 83.848254 178.138367 \nL 84.230029 178.138367 \nL 84.343749 176.869427 \nL 84.680847 176.869427 \nL 84.794567 175.822047 \nL 85.598731 175.822047 \nL 85.712451 173.42516 \nL 86.289174 173.42516 \nL 86.402894 173.888424 \nL 86.890266 173.888424 \nL 87.003986 172.216645 \nL 87.641631 172.216645 \nL 87.755351 169.980893 \nL 89.522073 169.980893 \nL 89.635793 162.226256 \nL 91.402516 162.226256 \nL 91.516236 154.8946 \nL 93.433231 154.8946 \nL 93.546951 146.757268 \nL 95.463947 146.757268 \nL 95.577667 140.311856 \nL 97.494662 140.311856 \nL 97.608382 133.242045 \nL 99.525378 133.242045 \nL 99.639098 124.198326 \nL 101.556093 124.198326 \nL 101.669813 114.348931 \nL 103.586809 114.348931 \nL 103.700529 106.413017 \nL 105.617524 106.413017 \nL 105.731244 97.711711 \nL 107.64824 97.711711 \nL 107.76196 89.473669 \nL 109.678955 89.473669 \nL 109.792675 82.021162 \nL 110.718681 82.021162 \nL 110.832401 80.168106 \nL 111.677179 80.168106 \nL 111.790899 77.952495 \nL 112.708782 77.952495 \nL 112.822503 74.810357 \nL 113.703833 74.810357 \nL 113.817553 72.332902 \nL 114.849157 72.332902 \nL 114.962877 68.888635 \nL 116.489975 68.888635 \nL 116.603695 65.303374 \nL 117.566254 65.303374 \nL 117.679974 63.389893 \nL 118.516629 63.389893 \nL 118.630349 61.657688 \nL 120.44987 61.657688 \nL 120.56359 55.796392 \nL 122.480585 55.796392 \nL 122.594305 55.051141 \nL 124.511301 55.051141 \nL 124.625021 54.30589 \nL 131.594436 54.30589 \nL 131.708157 59.46222 \nL 137.601293 59.46222 \nL 137.715013 59.8852 \nL 143.465999 59.8852 \nL 143.579719 56.09852 \nL 144.26204 56.09852 \nL 144.37576 56.904197 \nL 144.850947 56.904197 \nL 144.964667 59.099665 \nL 145.350503 59.099665 \nL 145.464223 61.556979 \nL 145.878489 61.556979 \nL 145.992209 64.618549 \nL 146.512072 64.618549 \nL 146.625792 69.613744 \nL 148.315348 69.613744 \nL 148.429068 66.008341 \nL 150.346063 66.008341 \nL 150.459783 60.650593 \nL 152.376779 60.650593 \nL 152.490499 60.167187 \nL 153.859201 60.167187 \nL 153.972921 62.886345 \nL 164.012778 62.886345 \nL 164.126498 57.730015 \nL 166.149091 57.730015 \nL 166.262811 67.277282 \nL 168.179807 67.277282 \nL 168.293527 66.854302 \nL 169.585062 66.854302 \nL 169.698782 69.956156 \nL 173.646493 69.956156 \nL 173.760213 68.828209 \nL 175.677208 68.828209 \nL 175.790928 62.705068 \nL 177.707924 62.705068 \nL 177.821644 55.554689 \nL 179.738639 55.554689 \nL 179.852359 47.961188 \nL 181.769355 47.961188 \nL 181.883075 40.50868 \nL 183.80007 40.50868 \nL 183.91379 33.579863 \nL 185.830786 33.579863 \nL 185.944506 32.451915 \nL 191.922932 32.451915 \nL 192.036652 29.732757 \nL 206.13794 29.732757 \nL 206.25166 20.185491 \nL 210.199371 20.185491 \nL 210.313091 17.083636 \nL 225.547519 17.083636 \nL 225.669362 31.364252 \nL 225.714038 31.364252 \nL 225.827758 40.851093 \nL 225.884618 40.851093 \nL 226.006461 69.774879 \nL 226.014583 69.774879 \nL 226.136426 99.38349 \nL 226.254208 99.38349 \nL 226.376051 128.367702 \nL 226.384174 128.367702 \nL 226.501955 147.764363 \nL 226.595368 147.764363 \nL 226.71315 166.959606 \nL 226.725334 166.959606 \nL 226.843115 186.678538 \nL 226.924344 186.678538 \nL 227.038064 195.984101 \nL 227.086801 195.984101 \nL 227.200521 205.249381 \nL 229.117517 205.249381 \nL 229.231237 200.798018 \nL 229.962294 200.798018 \nL 230.076014 196.850204 \nL 230.413113 196.850204 \nL 230.522772 195.198567 \nL 230.526833 195.500695 \nL 231.261952 195.500695 \nL 231.375672 192.056428 \nL 231.846798 192.056428 \nL 231.960518 189.377554 \nL 232.301679 189.377554 \nL 232.415399 187.323079 \nL 232.53318 187.323079 \nL 232.6469 186.376409 \nL 232.784989 186.376409 \nL 232.898709 185.32903 \nL 234.815704 185.32903 \nL 234.929424 176.043608 \nL 236.84642 176.043608 \nL 236.96014 166.194213 \nL 238.877135 166.194213 \nL 238.990855 156.344818 \nL 240.907851 156.344818 \nL 241.021571 146.475281 \nL 242.938566 146.475281 \nL 243.052286 136.948156 \nL 244.969282 136.948156 \nL 245.083002 127.380748 \nL 246.999997 127.380748 \nL 247.113717 117.752914 \nL 249.030713 117.752914 \nL 249.144433 107.883377 \nL 251.061428 107.883377 \nL 251.175148 98.033982 \nL 253.092144 98.033982 \nL 253.205864 88.728418 \nL 255.122859 88.728418 \nL 255.236579 79.463139 \nL 259.18429 79.463139 \nL 259.29801 73.5817 \nL 261.215006 73.5817 \nL 261.328726 65.746496 \nL 263.245721 65.746496 \nL 263.359441 56.219372 \nL 265.276437 56.219372 \nL 265.390157 49.814244 \nL 267.307152 49.814244 \nL 267.420872 42.643723 \nL 269.337868 42.643723 \nL 269.451588 34.828661 \nL 271.368583 34.828661 \nL 271.482303 25.905794 \nL 273.399299 25.905794 \nL 273.513019 17.083636 \nL 315.09801 17.083636 \nL 315.227976 41.45535 \nL 315.232037 41.45535 \nL 315.35388 71.003536 \nL 315.378249 71.003536 \nL 315.500092 100.491295 \nL 315.516338 100.491295 \nL 315.638181 130.059622 \nL 315.650365 130.059622 \nL 315.772208 159.607808 \nL 315.780331 159.607808 \nL 315.902174 189.196277 \nL 315.906235 189.196277 \nL 316.024016 214.051397 \nL 316.194597 214.131964 \nL 316.312378 214.272958 \nL 316.43016 214.373667 \nL 316.564187 214.494519 \nL 316.690091 214.575086 \nL 316.807873 214.655654 \nL 319.305653 214.554945 \nL 319.378758 214.514661 \nL 319.415311 214.554945 \nL 320.284458 214.454235 \nL 320.4063 214.313242 \nL 320.524082 214.252816 \nL 320.641863 214.111822 \nL 320.727154 214.011113 \nL 320.848996 213.890261 \nL 321.718143 213.809694 \nL 321.831863 210.526562 \nL 322.445139 210.526562 \nL 322.558859 207.122579 \nL 322.973125 207.122579 \nL 323.086845 204.60484 \nL 323.521418 204.60484 \nL 323.635138 202.449655 \nL 324.03722 202.449655 \nL 324.15094 200.193761 \nL 324.593636 200.193761 \nL 324.707356 197.635738 \nL 325.129745 197.635738 \nL 325.243465 195.198567 \nL 325.702406 195.198567 \nL 325.816127 192.580118 \nL 326.246638 192.580118 \nL 326.360358 190.122805 \nL 326.8193 190.122805 \nL 326.93302 187.524498 \nL 327.400085 187.524498 \nL 327.513805 184.885908 \nL 328.025545 184.885908 \nL 328.139265 182.086182 \nL 328.659128 182.086182 \nL 328.772848 179.165605 \nL 329.31708 179.165605 \nL 329.4308 176.144318 \nL 330.190288 176.144318 \nL 330.304008 172.035368 \nL 331.04725 172.035368 \nL 331.16097 168.027127 \nL 332.188512 168.027127 \nL 332.302232 162.608953 \nL 334.219227 162.608953 \nL 334.332947 152.7797 \nL 336.249943 152.7797 \nL 336.363663 142.930304 \nL 338.280658 142.930304 \nL 338.394378 136.364041 \nL 340.311374 136.364041 \nL 340.425094 129.898487 \nL 341.765366 129.898487 \nL 341.879086 125.306131 \nL 342.780724 125.306131 \nL 342.894444 120.592924 \nL 343.568641 120.592924 \nL 343.682361 119.08228 \nL 344.222532 119.08228 \nL 344.336252 118.397455 \nL 345.343487 118.357171 \nL 345.457207 118.256462 \nL 346.513179 118.196036 \nL 346.626899 117.994617 \nL 347.122393 117.994617 \nL 347.236113 117.81334 \nL 347.650379 117.81334 \nL 347.764099 118.075185 \nL 348.166181 118.075185 \nL 348.279901 118.619016 \nL 348.775396 118.619016 \nL 348.889116 118.739868 \nL 349.701402 118.739868 \nL 349.815122 117.410502 \nL 351.732118 117.410502 \nL 351.845838 111.670057 \nL 352.869318 111.670057 \nL 352.869318 111.670057 \n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 224.64 \nL 33.2875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 368.0875 224.64 \nL 368.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 224.64 \nL 368.0875 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 7.2 \nL 368.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p18bd3fa325\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"33.2875\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(returns, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👷 Provavelmente tem alguma coisa errado 👷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bitpy38condab8c15842aa23458397db80a1150fb412",
   "display_name": "Python 3.8.0 64-bit ('py38': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximal Policy Optimization (PPO)\n",
    "\n",
    "Como vimos na aula de A2C, uma função objetivo muito utilizada é:\n",
    "\n",
    "$$\n",
    "    J(\\theta) =  \\mathbb{E}_{s,a\\sim\\pi_\\theta} [A^{\\pi_\\theta}_w(s,a)], \\qquad\n",
    "    \\nabla_\\theta J(\\theta) =  \\mathbb{E}_{s,a\\sim\\pi_\\theta} [\\nabla_\\theta \\log \\pi_\\theta(a|s)\\cdot A^{\\pi_\\theta}_w(s,a)].\n",
    "$$\n",
    "\n",
    "Os índices na função _advantage_ $A$ indicam que $A$ depende tanto dos pesos $w$ utilizados para calcular o estimar de cada estado, quanto da política $\\pi_\\theta$, que determina quais trajetórias o agente vai seguir dentro do ambiente.\n",
    "\n",
    "> Obs: pode-se mostrar que essa formulação é equivalente à formulação que utiliza somatórias no tempo:\n",
    "$$\n",
    "    J(\\theta) =  \\mathbb{E}_{(s_0,a_0,\\dots)\\sim\\pi_\\theta} \\left[\\sum_{t=0}^\\infty \\gamma^t A^{\\pi_\\theta}_w(s_t,a_t)\\right], \\qquad\n",
    "    \\nabla_\\theta J(\\theta) =  \\mathbb{E}_{(s_0,a_0,\\dots)\\sim\\pi_\\theta} \\left[\\sum_{t=0}^\\infty \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t)\\cdot A^{\\pi_\\theta}_w(s_t,a_t)\\right].\n",
    "$$\n",
    "\n",
    "Note que uma pequena variação no espaço de parâmetros ($\\Delta\\theta = \\alpha\\nabla_\\theta J$) pode causar uma grande variação no espaço de políticas. Isso significa que, em geral, a taxa de aprendizado $\\alpha$ não pode ser muito alta; caso contrário, corremos o risco de obter uma nova política que não funcione. Consequentemente, a eficiência amostral de A2C também é limitada.\n",
    "\n",
    "\n",
    "## Trust Region Policy Optimization (TRPO)\n",
    "\n",
    "Uma maneira de resolver esse problema é limitar as variações na política. Para isso, vamos utilizar a divergência KL $KL(\\pi_1 || \\pi_2)$, que pode ser, simplificadamente, encarada como uma medida da diferença entre duas políticas (ou, em geral, duas distribuições de probabilidade).\n",
    "\n",
    "TRPO define uma região de confiança (trust region) para garantir que a política nova não se distancie demais da política antiga:\n",
    "$$E_{s\\sim\\pi_{\\theta_{\\mathrm{old}}}}\\bigl[KL\\bigl(\\pi_{\\mathrm{old}}(\\cdot|s)\\,||\\,\\pi(\\cdot|s)\\bigr)\\bigr] \\le \\delta.$$\n",
    "\n",
    "No entanto, maximizar a função objetivo de A2C sujeito a essas restrições é um pouco complicado. Então, vamos utilizar uma aproximação da função objetivo de A2C:\n",
    "\n",
    "$$L(\\theta_{\\mathrm{old}},\\theta) = E_{s,a\\sim\\pi_{\\theta_{\\mathrm{old}}}} \\left[\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)} A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a)\\right].$$\n",
    "\n",
    "Ou seja, TRPO consiste em:\n",
    "$$\\text{maximizar } E_{s,a\\sim\\pi_{\\theta_{\\mathrm{old}}}} \\left[\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)} A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a)\\right] \\text{ sujeito a } E_{s\\sim\\pi_{\\theta_{\\mathrm{old}}}}\\bigl[KL\\bigl(\\pi_{\\mathrm{old}}(\\cdot|s)\\,||\\,\\pi(\\cdot|s)\\bigr)\\bigr] \\le \\delta.$$\n",
    "\n",
    "> Para entender como chegamos $L(\\theta_{\\mathrm{old}},\\theta)$ é uma aproximação de $J(\\theta)$, podemos fazer:\n",
    "\\begin{align*}\n",
    "J(\\theta) &= E_{\\pi_\\theta}[A^{\\pi_\\theta}(s,a)] \\\\\n",
    "        &= E_{\\pi_\\theta}[A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a)] \\\\\n",
    "\t\t&= \\sum_{s,a} \\rho_{\\pi_\\theta}(s)\\cdot \\pi_\\theta(a|s) \\cdot A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a) \\\\\n",
    "\t\t&= \\sum_{s,a} \\rho_{\\pi_\\theta}(s)\\cdot \\pi_{\\theta_{\\mathrm{old}}}(a|s) \\cdot \\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)}A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a) \\\\\n",
    "\t\t&\\approx \\sum_{s,a} \\rho_{\\pi_{\\theta_{\\mathrm{old}}}}(s)\\cdot \\pi_{\\theta_{\\mathrm{old}}}(a|s) \\cdot \\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)}A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a) \\\\\n",
    "\t\t&= E_{\\pi_{\\theta_{\\mathrm{old}}}} \\left[\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)} A^{\\pi_\\theta}(s,a)\\right]\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "## Proximal Policy Optimization (PPO)\n",
    "\n",
    "Como já foi mencionado, a restrição ($KL < \\delta$) imposta em TRPO torna o algoritmo relativamente complicado. PPO é uma tentativa de simplificar esse algoritmo. Ao invés de utilizar trust regions, PPO mexe diretamente com a função objetivo:\n",
    "\n",
    "$$\n",
    "    L(\\theta_{\\mathrm{old}},\\theta) = E_{s,a\\sim\\pi_{\\theta_{\\mathrm{old}}}} \\Bigl[\\min\\left(r A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a),\\, \\operatorname{clip}(r,1-\\varepsilon,1+\\varepsilon) A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a)\\right)\\Bigr],\n",
    "    \\quad\n",
    "    r = \\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)}.\n",
    "$$\n",
    "Essa função pode ser reescrita como:\n",
    "$$\n",
    "    L(\\theta_{\\mathrm{old}},\\theta) = E_{s,a\\sim\\pi_{\\theta_{\\mathrm{old}}}} \\Bigl[\\min\\left(r A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a),\\, g(\\varepsilon, A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a))\\right)\\Bigr],\n",
    "    \\quad\n",
    "    g(\\varepsilon, A) = \\begin{cases}\n",
    "        (1+\\varepsilon) A, & A \\ge 0 \\\\\n",
    "        (1-\\varepsilon) A,  & A < 0.\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "Nota-se que:\n",
    "- Quando a vantagem é positiva, se $r$ aumentar, então $L$ aumenta. No entanto, esse benefício é limitado pelo clip: se $r > 1+\\varepsilon$, não há mais benefício para $r$ aumentar.\n",
    "- Quando a vantagem é negativa, se $r$ diminuir, então $L$ aumenta. No entanto, esse benefício é limitado pelo clip: se $r < 1-\\varepsilon$, não há mais benefício para $r$ diminuir.\n",
    "\n",
    "A seguinte imagem pode te ajudar a visualizar o clip. Note que todos os valores fora do clip estipulado estão constantes:\n",
    "\n",
    "![imagem ilustrando o clip](imgs/clip.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Divida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, observation_shape, action_shape):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.policy1 = nn.Linear(observation_shape, 64)\n",
    "        self.policy2 = nn.Linear(64, 64)\n",
    "        self.policy3 = nn.Linear(64, action_shape)\n",
    "        \n",
    "        self.value1 = nn.Linear(observation_shape, 64)\n",
    "        self.value2 = nn.Linear(64, 64)\n",
    "        self.value3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        dists = torch.tanh(self.policy1(state))\n",
    "        dists = torch.tanh(self.policy2(dists))\n",
    "        dists = F.softmax(self.policy3(dists), dim=-1)\n",
    "        probs = Categorical(dists)\n",
    "        \n",
    "        v = torch.tanh(self.value1(state))\n",
    "        v = torch.tanh(self.value2(v))\n",
    "        v = self.value3(v)\n",
    "\n",
    "        return probs, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ExperienceReplay:\n",
    "    \"\"\"Experience Replay Buffer para PPO.\"\"\"\n",
    "    def __init__(self, max_length, observation_space):\n",
    "        \"\"\"Cria um Replay Buffer.\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        max_length: int\n",
    "            Tamanho máximo do Replay Buffer.\n",
    "        observation_space: int\n",
    "            Tamanho do espaço de observação.\n",
    "        \"\"\"\n",
    "        self.length = 0\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.states = np.zeros((max_length, observation_space), dtype=np.float32)\n",
    "        self.actions = np.zeros((max_length), dtype=np.int32)\n",
    "        self.rewards = np.zeros((max_length), dtype=np.float32)\n",
    "        self.next_states = np.zeros((max_length, observation_space), dtype=np.float32)\n",
    "        self.dones = np.zeros((max_length), dtype=np.float32)\n",
    "        self.logp = np.zeros((max_length), dtype=np.float32)\n",
    "\n",
    "    def update(self, states, actions, rewards, next_states, dones, logp):\n",
    "        \"\"\"Adiciona uma experiência ao Replay Buffer.\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        state: np.array\n",
    "            Estado da transição.\n",
    "        action: int\n",
    "            Ação tomada.\n",
    "        reward: float\n",
    "            Recompensa recebida.\n",
    "        state: np.array\n",
    "            Estado seguinte.\n",
    "        done: int\n",
    "            Flag indicando se o episódio acabou.\n",
    "        logp: float\n",
    "            Log da probabildiade de acordo com a política.\n",
    "        \"\"\"\n",
    "        self.states[self.length] = states\n",
    "        self.actions[self.length] = actions\n",
    "        self.rewards[self.length] = rewards\n",
    "        self.next_states[self.length] = next_states\n",
    "        self.dones[self.length] = dones\n",
    "        self.logp[self.length] = logp\n",
    "        self.length += 1\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Retorna um batch de experiências.\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            Tamanho do batch de experiências.\n",
    "\n",
    "        Retorna\n",
    "        -------\n",
    "        states: np.array\n",
    "            Batch de estados.\n",
    "        actions: np.array\n",
    "            Batch de ações.\n",
    "        rewards: np.array\n",
    "            Batch de recompensas.\n",
    "        next_states: np.array\n",
    "            Batch de estados seguintes.\n",
    "        dones: np.array\n",
    "            Batch de flags indicando se o episódio acabou.\n",
    "        logp: np.array\n",
    "            Batch do log da probabildiade de acordo com a política.\n",
    "        \"\"\"\n",
    "        self.length = 0\n",
    "\n",
    "        return (self.states, self.actions, self.rewards, self.next_states, self.dones, self.logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class PPO:\n",
    "    def __init__(self, observation_space, action_space, lr=7e-4, gamma=0.99, lam=0.95, vf_coef=0.5, entropy_coef=0.005,clip_param =0.2, epochs =10, n_steps=5):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "        self.vf_coef = vf_coef\n",
    "        self.entropy_coef = entropy_coef\n",
    "        self.clip_param = clip_param\n",
    "        self.epochs = epochs\n",
    "\n",
    "        self.n_steps = n_steps\n",
    "        self.memory = ExperienceReplay(n_steps, observation_space.shape[0])\n",
    "\n",
    "        self.actorcritic = ActorCritic(observation_space.shape[0], action_space.n).to(self.device)\n",
    "        self.actorcritic_optimizer = optim.Adam(self.actorcritic.parameters(), lr=lr)\n",
    "\n",
    "    def act(self, state):\n",
    "        state = torch.FloatTensor(state).to(self.device).unsqueeze(0)\n",
    "        probs, v = self.actorcritic.forward(state)\n",
    "        action = probs.sample()\n",
    "        log_prob = probs.log_prob(action)\n",
    "        return action.cpu().detach().item(), log_prob.detach().cpu().numpy()\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done, logp):\n",
    "        self.memory.update(state, action, reward, next_state, done, logp)\n",
    "\n",
    "    def compute_gae(self, rewards, dones, v, v2):\n",
    "        T = len(rewards)\n",
    "\n",
    "        returns = torch.zeros_like(rewards)\n",
    "        gaes = torch.zeros_like(rewards)\n",
    "        \n",
    "        future_gae = torch.tensor(0.0, dtype=rewards.dtype)\n",
    "        next_return = torch.tensor(v2[-1], dtype=rewards.dtype)\n",
    "\n",
    "        not_dones = 1 - dones\n",
    "        deltas = rewards + not_dones * self.gamma * v2 - v\n",
    "\n",
    "        for t in reversed(range(T)):\n",
    "            returns[t] = next_return = rewards[t] + self.gamma * not_dones[t] * next_return\n",
    "            gaes[t] = future_gae = deltas[t] + self.gamma * self.lam * not_dones[t] * future_gae\n",
    "\n",
    "        gaes = (gaes - gaes.mean()) / (gaes.std() + 1e-8) # Normalização\n",
    "\n",
    "        return gaes, returns\n",
    "\n",
    "    def train(self):\n",
    "        if self.memory.length < self.n_steps:\n",
    "            return\n",
    "\n",
    "        (states, actions, rewards, next_states, dones, old_logp) = self.memory.sample()\n",
    "\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.FloatTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).unsqueeze(-1).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).unsqueeze(-1).to(self.device)\n",
    "        old_logp = torch.FloatTensor(old_logp).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, v = self.actorcritic.forward(states)\n",
    "            _, v2 = self.actorcritic.forward(next_states)\n",
    "        \n",
    "        advantages, returns = self.compute_gae(rewards, dones, v, v2)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            probs, v = self.actorcritic.forward(states)\n",
    "\n",
    "            new_logp = probs.log_prob(actions)\n",
    "\n",
    "            #Equações principais do algoritmo\n",
    "            ratio = (new_logp.unsqueeze(-1) - old_logp.unsqueeze(-1)).exp() \n",
    "            surr1 = ratio * advantages.detach()\n",
    "            surr2 = torch.clamp(ratio, 1.0 - self.clip_param, 1.0 + self.clip_param) * advantages.detach()\n",
    "\n",
    "            entropy = probs.entropy().mean()\n",
    "\n",
    "            policy_loss =   - torch.min(surr1,surr2).mean()\n",
    "            value_loss =    self.vf_coef * F.mse_loss(v, returns.detach())\n",
    "            entropy_loss = -self.entropy_coef * entropy\n",
    "\n",
    "            self.actorcritic_optimizer.zero_grad()\n",
    "            (policy_loss + entropy_loss + value_loss).backward()\n",
    "            self.actorcritic_optimizer.step()\n",
    "\n",
    "        return policy_loss + entropy_loss + value_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import deque\n",
    "\n",
    "def train(agent, env, total_timesteps):\n",
    "    total_reward = 0\n",
    "    episode_returns = deque(maxlen=20)\n",
    "    avg_returns = []\n",
    "\n",
    "    state = env.reset()\n",
    "    timestep = 0\n",
    "    episode = 0\n",
    "\n",
    "    while timestep < total_timesteps:\n",
    "        action, log_prob = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.remember(state, action, reward, next_state, done, log_prob)\n",
    "        loss = agent.train()\n",
    "        timestep += 1\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "        if done:\n",
    "            episode_returns.append(total_reward)\n",
    "            episode += 1\n",
    "            next_state = env.reset()\n",
    "\n",
    "        if episode_returns:\n",
    "            avg_returns.append(np.mean(episode_returns))\n",
    "\n",
    "        total_reward *= 1 - done\n",
    "        state = next_state\n",
    "\n",
    "        ratio = math.ceil(100 * timestep / total_timesteps)\n",
    "\n",
    "        avg_return = avg_returns[-1] if avg_returns else np.nan\n",
    "        \n",
    "        print(f\"\\r[{ratio:3d}%] timestep = {timestep}/{total_timesteps}, episode = {episode:3d}, avg_return = {avg_return:10.4f}\", end=\"\")\n",
    "\n",
    "    return avg_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[100%] timestep = 75000/75000, episode = 452, avg_return =   295.3500"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "agente = PPO(env.observation_space, env.action_space)\n",
    "returns = train(agente, env, 75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 375.2875 248.518125\" width=\"375.2875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-11-03T14:11:12.499167</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 375.2875 248.518125 \nL 375.2875 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 224.64 \nL 368.0875 224.64 \nL 368.0875 7.2 \nL 33.2875 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mf5be463877\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.505682\" xlink:href=\"#mf5be463877\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(45.324432 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"89.095618\" xlink:href=\"#mf5be463877\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10000 -->\n      <g transform=\"translate(73.189368 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.685554\" xlink:href=\"#mf5be463877\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 20000 -->\n      <g transform=\"translate(113.779304 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"170.27549\" xlink:href=\"#mf5be463877\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 30000 -->\n      <g transform=\"translate(154.36924 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"210.865426\" xlink:href=\"#mf5be463877\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 40000 -->\n      <g transform=\"translate(194.959176 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"251.455363\" xlink:href=\"#mf5be463877\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 50000 -->\n      <g transform=\"translate(235.549113 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"292.045299\" xlink:href=\"#mf5be463877\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 60000 -->\n      <g transform=\"translate(276.139049 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"332.635235\" xlink:href=\"#mf5be463877\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 70000 -->\n      <g transform=\"translate(316.728985 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mbec3324af0\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mbec3324af0\" y=\"218.420698\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0 -->\n      <g transform=\"translate(19.925 222.219917)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mbec3324af0\" y=\"178.153286\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 181.952505)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mbec3324af0\" y=\"137.885873\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 200 -->\n      <g transform=\"translate(7.2 141.685092)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mbec3324af0\" y=\"97.618461\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 300 -->\n      <g transform=\"translate(7.2 101.41768)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mbec3324af0\" y=\"57.351049\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 400 -->\n      <g transform=\"translate(7.2 61.150267)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mbec3324af0\" y=\"17.083636\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 500 -->\n      <g transform=\"translate(7.2 20.882855)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#pb816f6c3cf)\" d=\"M 48.505682 212.380586 \nL 48.542213 212.380586 \nL 48.643688 213.588609 \nL 48.655865 213.387272 \nL 48.680219 213.387272 \nL 48.797929 214.091951 \nL 48.862873 214.170249 \nL 48.948112 214.24753 \nL 48.976525 214.226176 \nL 49.138885 214.293288 \nL 49.252537 214.35157 \nL 49.378365 214.454358 \nL 49.455486 214.595294 \nL 49.500135 214.555027 \nL 50.372819 214.655695 \nL 50.494589 214.716096 \nL 50.738128 214.615428 \nL 50.859898 214.555027 \nL 51.988298 214.635561 \nL 52.028888 214.675829 \nL 52.10195 214.655695 \nL 54.20045 214.635561 \nL 54.314102 214.454358 \nL 54.318161 214.454358 \nL 54.435871 213.669144 \nL 54.533287 213.669144 \nL 54.650998 213.065132 \nL 54.707824 213.065132 \nL 54.821476 212.78326 \nL 54.849889 212.78326 \nL 54.963541 212.56179 \nL 55.227375 212.56179 \nL 55.341027 210.870558 \nL 55.454679 210.508152 \nL 55.580508 210.508152 \nL 55.69416 209.501466 \nL 55.742867 209.501466 \nL 55.856519 208.776653 \nL 55.880873 208.776653 \nL 55.994525 208.454514 \nL 56.165003 208.43438 \nL 56.294891 209.783338 \nL 56.319245 209.783338 \nL 56.441014 210.568553 \nL 56.469427 210.568553 \nL 56.587138 214.253021 \nL 56.656141 214.35369 \nL 56.769793 214.675829 \nL 57.057981 214.57516 \nL 57.094512 214.534893 \nL 57.171633 214.555027 \nL 57.200046 214.555027 \nL 57.317757 214.333556 \nL 57.46794 214.232887 \nL 57.610005 214.071818 \nL 57.881957 213.971149 \nL 57.963137 213.890614 \nL 57.995609 213.930882 \nL 58.409626 213.930882 \nL 58.523278 213.689277 \nL 58.714051 213.64901 \nL 58.827703 213.004731 \nL 58.835821 213.004731 \nL 58.949472 212.56179 \nL 59.205189 212.56179 \nL 59.318841 210.910826 \nL 59.424375 210.910826 \nL 59.538026 210.045076 \nL 59.635442 210.045076 \nL 59.749094 209.219594 \nL 59.773448 209.219594 \nL 59.8871 208.756519 \nL 59.919572 208.756519 \nL 60.033224 208.313578 \nL 60.114404 208.313578 \nL 60.228055 207.568631 \nL 60.642073 207.568631 \nL 60.755725 205.132452 \nL 60.877494 205.132452 \nL 60.991146 204.186168 \nL 61.664939 204.186168 \nL 61.778591 200.5017 \nL 62.302201 200.5017 \nL 62.415853 197.562179 \nL 62.525446 197.562179 \nL 62.639098 196.716563 \nL 62.777103 196.716563 \nL 62.890755 195.689744 \nL 63.065292 195.689744 \nL 63.178944 194.461588 \nL 63.239829 194.461588 \nL 63.35348 193.636106 \nL 63.365657 193.636106 \nL 63.479309 193.958245 \nL 63.523958 193.958245 \nL 63.63761 194.562256 \nL 64.100335 194.562256 \nL 64.213987 192.307281 \nL 64.628004 192.307281 \nL 64.741656 191.522067 \nL 65.626517 191.522067 \nL 65.740169 187.656395 \nL 66.093301 187.656395 \nL 66.206953 186.387972 \nL 66.401785 186.387972 \nL 66.515436 185.542356 \nL 67.018752 185.542356 \nL 67.132404 183.206846 \nL 67.623542 183.206846 \nL 67.737194 181.173342 \nL 68.926479 181.173342 \nL 69.040131 177.327804 \nL 69.758572 177.327804 \nL 69.872224 174.368149 \nL 71.788069 174.368149 \nL 71.901721 168.207235 \nL 72.855585 168.207235 \nL 72.969236 166.073062 \nL 74.223465 166.073062 \nL 74.292468 160.395357 \nL 74.337117 161.301374 \nL 74.349294 161.301374 \nL 74.462946 162.972471 \nL 75.428986 162.972471 \nL 75.542638 158.40212 \nL 76.208313 158.40212 \nL 76.321965 154.43578 \nL 76.951109 154.43578 \nL 77.064761 151.516393 \nL 77.685787 151.516393 \nL 77.799439 148.174197 \nL 78.647768 148.174197 \nL 78.76142 146.261495 \nL 79.418977 146.261495 \nL 79.532629 145.053473 \nL 80.454021 145.053473 \nL 80.567672 144.872269 \nL 81.549949 144.872269 \nL 81.663601 141.751545 \nL 82.722998 141.751545 \nL 82.83665 137.463066 \nL 84.025935 137.463066 \nL 84.139587 134.060469 \nL 86.055432 134.060469 \nL 86.169084 126.993538 \nL 87.83733 126.993538 \nL 87.950982 124.617761 \nL 89.866827 124.617761 \nL 89.980479 118.678318 \nL 93.92582 118.678318 \nL 94.039472 113.906629 \nL 95.955317 113.906629 \nL 96.068969 110.624835 \nL 97.984814 110.624835 \nL 98.098466 100.900255 \nL 100.014311 100.900255 \nL 100.127963 91.115274 \nL 102.043808 91.115274 \nL 102.157459 81.390694 \nL 104.073304 81.390694 \nL 104.186956 76.337134 \nL 106.102801 76.337134 \nL 106.216453 70.135952 \nL 108.132298 70.135952 \nL 108.24595 60.552308 \nL 110.161795 60.552308 \nL 110.275447 53.686714 \nL 112.191292 53.686714 \nL 112.304943 47.264062 \nL 114.220788 47.264062 \nL 114.33444 41.968897 \nL 116.250285 41.968897 \nL 116.363937 35.727448 \nL 118.279782 35.727448 \nL 118.393434 30.79469 \nL 120.309279 30.79469 \nL 120.422931 26.163938 \nL 122.338776 26.163938 \nL 122.452428 21.915726 \nL 124.368273 21.915726 \nL 124.481924 18.311792 \nL 128.427266 18.311792 \nL 128.540918 17.083636 \nL 202.78397 17.083636 \nL 202.897622 20.727837 \nL 204.578045 20.727837 \nL 204.691697 21.895592 \nL 217.509999 21.895592 \nL 217.623651 28.217576 \nL 218.934706 28.217576 \nL 219.048358 31.217498 \nL 241.259171 31.217498 \nL 241.372823 27.573297 \nL 243.288668 27.573297 \nL 243.402319 26.405542 \nL 257.495145 26.405542 \nL 257.608797 20.083559 \nL 259.524642 20.083559 \nL 259.638294 17.083636 \nL 290.222811 17.083636 \nL 290.336463 25.882066 \nL 294.375161 25.962601 \nL 294.492872 45.049354 \nL 294.602465 45.049354 \nL 294.724235 74.182827 \nL 294.801355 74.182827 \nL 294.915007 83.70607 \nL 294.967774 83.70607 \nL 295.081426 92.947441 \nL 301.997951 92.947441 \nL 302.131898 127.959956 \nL 302.152193 127.959956 \nL 302.273963 157.415568 \nL 304.295342 157.415568 \nL 304.408993 148.617139 \nL 304.940722 148.617139 \nL 305.054373 155.482733 \nL 305.573925 155.482733 \nL 305.687576 162.328193 \nL 305.975765 162.328193 \nL 306.089417 160.878566 \nL 306.381664 160.878566 \nL 306.495316 159.368538 \nL 306.937746 159.348404 \nL 307.051398 157.335034 \nL 307.152873 157.335034 \nL 307.266525 157.15383 \nL 307.530359 157.15383 \nL 307.644011 156.106878 \nL 308.719645 156.106878 \nL 308.833296 160.274555 \nL 310.347301 160.274555 \nL 310.460953 162.267792 \nL 311.317401 162.267792 \nL 311.431052 167.522689 \nL 312.535099 167.522689 \nL 312.64875 166.153597 \nL 314.564595 166.153597 \nL 314.678247 156.308215 \nL 315.737645 156.308215 \nL 315.851296 150.650643 \nL 316.56162 150.650643 \nL 316.675272 146.764838 \nL 317.795554 146.764838 \nL 317.909206 140.825395 \nL 318.41658 140.825395 \nL 318.530232 137.986542 \nL 318.972662 137.986542 \nL 319.086314 135.550364 \nL 320.019883 135.550364 \nL 320.133535 140.42272 \nL 320.75862 140.42272 \nL 320.872271 139.959645 \nL 321.265994 139.959645 \nL 321.379646 140.58379 \nL 321.830194 140.58379 \nL 321.943846 139.778442 \nL 322.004731 139.778442 \nL 322.118383 140.926063 \nL 322.183326 140.926063 \nL 322.296978 140.684459 \nL 322.309155 140.684459 \nL 322.406571 142.174353 \nL 322.422807 142.033417 \nL 322.516164 142.033417 \nL 322.629816 142.21462 \nL 322.637934 142.21462 \nL 322.751586 143.483044 \nL 322.779998 143.483044 \nL 322.89365 148.67754 \nL 323.019479 148.67754 \nL 323.133131 155.563267 \nL 323.141249 155.563267 \nL 323.254901 159.771212 \nL 323.319845 159.771212 \nL 323.433496 164.925441 \nL 323.470027 164.925441 \nL 323.583679 174.247347 \nL 323.794747 174.247347 \nL 323.908399 178.455291 \nL 324.216882 178.455291 \nL 324.330534 180.448528 \nL 324.760787 180.448528 \nL 324.874439 183.871258 \nL 325.260044 183.871258 \nL 325.373695 184.47527 \nL 326.863346 184.47527 \nL 326.976998 179.280773 \nL 327.374779 179.280773 \nL 327.488431 181.938423 \nL 329.22568 181.938423 \nL 329.339332 176.421787 \nL 329.802057 176.421787 \nL 329.915709 176.079514 \nL 330.528617 176.079514 \nL 330.642269 175.274166 \nL 331.28359 175.274166 \nL 331.397242 172.395046 \nL 332.428226 172.395046 \nL 332.541878 167.603224 \nL 333.09796 167.603224 \nL 333.211612 164.905307 \nL 333.844815 164.905307 \nL 333.958467 161.683914 \nL 334.896094 161.683914 \nL 335.009746 157.012894 \nL 335.651067 157.012894 \nL 335.764719 153.872036 \nL 336.422276 153.872036 \nL 336.535928 150.751312 \nL 337.826688 150.751312 \nL 337.94034 144.972938 \nL 339.113389 144.972938 \nL 339.227041 139.194564 \nL 339.957659 139.194564 \nL 340.071311 135.892637 \nL 341.163181 135.892637 \nL 341.276832 130.657873 \nL 343.010023 130.657873 \nL 343.123675 123.107733 \nL 344.751331 123.107733 \nL 344.864983 116.564279 \nL 346.780828 116.564279 \nL 346.89448 109.195342 \nL 348.810325 109.195342 \nL 348.923976 101.604935 \nL 350.839821 101.604935 \nL 350.953473 99.490896 \nL 352.869318 99.490896 \nL 352.869318 99.490896 \n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 224.64 \nL 33.2875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 368.0875 224.64 \nL 368.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 224.64 \nL 368.0875 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 7.2 \nL 368.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pb816f6c3cf\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"33.2875\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(returns, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O agente demonstra que aprende a solucionar o ambiente em menos de 20000 timesteps. Porém acaba desaprendendo, para solucionar isso é possível fazer uma otimização nos hiper-parâmetros. É possível também implementar algum tipo de parada antecipada."
   ]
  }
 ]
}
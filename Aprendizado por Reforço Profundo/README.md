# üß† Aprendizado por Refor√ßo Profundo

## [Deep Q-Learning](Deep%20Q-Learning)

Um dos algoritmos mais comuns em aprendizado por refor√ßo, quando se trata de aprendizado profundo, √© o **Deep Q-Learning**, ou DQN na forma abreviada. DQN √© a vers√£o profunda do algoritmo cl√°ssico de Q-Learning, em que agora utilizamos uma rede neural que recebe nosso estado e devolve os Q-Valores para cada poss√≠vel a√ß√£o do nosso agente.

DQN's s√£o alternativas muito boas ao Q-Learning quando precisamos lidar com problemas que cont√™m diversos estados, tornando a computa√ß√£o mais leve e o aprendizado mais eficaz.

## [Policy Gradient](Policy%20Gradient)

Quase todos os m√©todos vistos anteriormente ([m√©todos tabulares](../Aprendizado%20por%20Refor√ßo$20Cl√°ssico) e [DQN](#Deep%20Q-Learning)) estimam a fun√ß√£o de valor √≥tima _Q_\*(_s_,_a_) e, a partir de de _Q_\*, obt√©m uma pol√≠tica (&epsilon;-)gulosa. Os m√©todos de policy gradient tem uma proposta alternativa: eles estimam diretamente a pol√≠tica √≥tima.

## [Actor Critic](Actor-Critic)

Os Actor Critics s√£o algoritmos de estado da arte que combinam estimadores de fun√ß√£o de valor, como a DQN, com estimadores de pol√≠tica √≥tima, como o Policy Gradient. Dessa forma, esses algoritmos tendem a ser bem mais robustos do que modelos individuais.
